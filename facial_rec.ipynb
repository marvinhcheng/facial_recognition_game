{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f91253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/marv/anaconda3/lib/python3.7/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/marv/anaconda3/lib/python3.7/site-packages (from opencv-python) (1.21.5)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already satisfied: face_recognition in /Users/marv/anaconda3/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: Pillow in /Users/marv/anaconda3/lib/python3.7/site-packages (from face_recognition) (9.0.1)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /Users/marv/anaconda3/lib/python3.7/site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: dlib>=19.7 in /Users/marv/anaconda3/lib/python3.7/site-packages (from face_recognition) (19.23.1)\n",
      "Requirement already satisfied: Click>=6.0 in /Users/marv/anaconda3/lib/python3.7/site-packages (from face_recognition) (8.0.4)\n",
      "Requirement already satisfied: numpy in /Users/marv/anaconda3/lib/python3.7/site-packages (from face_recognition) (1.21.5)\n",
      "Requirement already satisfied: importlib-metadata in /Users/marv/anaconda3/lib/python3.7/site-packages (from Click>=6.0->face_recognition) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/marv/anaconda3/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->face_recognition) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/marv/anaconda3/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->face_recognition) (3.7.0)\n",
      "Requirement already satisfied: imutils in /Users/marv/anaconda3/lib/python3.7/site-packages (0.5.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!{sys.executable} -m conda install -c conda-forge dlib -y\n",
    "!{sys.executable} -m pip install face_recognition\n",
    "!{sys.executable} -m pip install --upgrade imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e05b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c334efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_faces():\n",
    "    image_paths = list(paths.list_images('faces'))\n",
    "    known_encodings = []\n",
    "    known_names = []\n",
    "    # loop over the image paths\n",
    "    for (i, image_path) in enumerate(image_paths):\n",
    "        # extract the name from the image path\n",
    "        name = image_path.split(os.path.sep)[-2]\n",
    "        # load the input image and convert it from BGR\n",
    "        # RGB for dlib usage\n",
    "        image = cv2.imread(image_path)\n",
    "        # standardize input image sizes\n",
    "        cv2.resize(image, (100, 100), interpolation=cv2.INTER_LINEAR)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        #Use face_recognition to locate faces\n",
    "        boxes = face_recognition.face_locations(rgb,model='hog')\n",
    "        \n",
    "        # compute the facial embedding for the face\n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        for encoding in encodings:\n",
    "            known_encodings.append(encoding)\n",
    "            known_names.append(name)\n",
    "            \n",
    "    #save encodings along with their names in dictionary data\n",
    "    data = {\"encodings\": known_encodings, \"names\": known_names}\n",
    "    \n",
    "    #use pickle to save data into a file for later use\n",
    "    f = open(\"face_enc\", \"wb\")\n",
    "    f.write(pickle.dumps(data))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(image):\n",
    "\n",
    "    # load the default haarcascade\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # load the known faces and embeddings\n",
    "    data = pickle.loads(open('face_enc', \"rb\").read())\n",
    "\n",
    "    image = cv2.imread(image)\n",
    "    if image is None:\n",
    "        print(\"Invalid Image\")\n",
    "        quit()\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # convert image to greyscale for haarcascade\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # in my classifier, smoothing resulted in worse results so it is unused here\n",
    "    smooth = cv2.GaussianBlur(gray, (125,125), 0)\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=6,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # the facial embeddings for face in input\n",
    "    encodings = face_recognition.face_encodings(rgb)\n",
    "    names = []\n",
    "    # loop over the facial embeddings incase\n",
    "    # we have multiple embeddings for multiple fcaes\n",
    "    for encoding in encodings:\n",
    "        # compare encodings with encodings in data[\"encodings\"]\n",
    "        # matches contain array with boolean values and True for the embeddings it matches closely\n",
    "        # and False for rest\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"], encoding, 0.5)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "        # check for matches in data[]\n",
    "        if True in matches:\n",
    "            # find indices of True\n",
    "            matched_ids = [i for (i, b) in enumerate(matches) if b]\n",
    "            counts = {}\n",
    "            # loop over the matched indicies increment our matches\n",
    "            for i in matched_ids:\n",
    "                # check names\n",
    "                name = data[\"names\"][i]\n",
    "                #increase count for the name we got\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "                #set name which has highest count\n",
    "                name = max(counts, key=counts.get)\n",
    "                \n",
    "                # note, this code is intended for multiple faces in our dictionary. I only have Kanye\n",
    "                # I found it difficult to properly train my classifier so I stuck with one person\n",
    "                # to avoid excessive false positives. however, the code/game is meant to be scaled\n",
    "\n",
    "\n",
    "            # update the list of names\n",
    "            names.append(name)\n",
    "            # loop over the recognized faces\n",
    "            for ((x, y, w, h), name) in zip(faces, names):\n",
    "                # rescale the face coordinates\n",
    "                # draw the predicted face name on the image\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "                cv2.putText(image, name, (x, y), cv2.FONT_HERSHEY_DUPLEX, 0.75, (255, 255, 0), 1)\n",
    "                \n",
    "    # cv2.imshow(\"output\", image)\n",
    "    # This above line pops up a window with the output. \n",
    "    cv2.imwrite(\"./output.jpg\", image)\n",
    "    #cv2.waitKey(0)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fccd04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    learn_faces()\n",
    "    recognize_face(\"KanyeLookAlike.jpg\")\n",
    "    # to use, uncomment above line and replace sample_image with your intended jpeg.\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    x = input(\"Is there an update to the faces folder? (y/n)\")\n",
    "#    if x == \"y\":\n",
    "#        learn_faces()\n",
    "#    recognize_face()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
